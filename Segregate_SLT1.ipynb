{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NehaKumari500092077/Image-Processing/blob/main/Segregate_SLT1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "segregate signal"
      ],
      "metadata": {
        "id": "Ex4C16JPzpgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wfdb\n",
        "segregate_signal_data = []\n",
        "record_no = []\n",
        "\n",
        "def segregateSignal(signal, length, fs):\n",
        "   range1 = 0\n",
        "   range2 = fs * 10\n",
        "   n = int(length/(fs * 10))\n",
        "   print(\"n: \", n)\n",
        "   for i in range(n):\n",
        "    #print(\"i and range1 and range2: \",i,\", \",range1,\", \",range2)\n",
        "    segregate_signal_data.append(signal[range1:range2])\n",
        "    range1 = range2\n",
        "    range2 = range2 + (fs * 10)\n",
        "\n",
        "for i in range(210, 235):\n",
        "      try:\n",
        "        path = '/content/drive/MyDrive/Dataset/mit-bih-arrhythmia-database-1.0.0/'\n",
        "        signal, fields = wfdb.rdsamp(path+str(i), channels=[0])\n",
        "        fs =  fields['fs'] # sampling frequency\n",
        "        record_no.append(i)\n",
        "        print(\"RECORD No. \", i)\n",
        "        segregateSignal(signal, fields['sig_len'], fs)\n",
        "      except FileNotFoundError:\n",
        "        continue\n",
        "\n",
        "print(\"segregate_signal_data: \", len(segregate_signal_data))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_95HkqEizuWt",
        "outputId": "1681a6bd-bb0f-4685-eafd-bc2cfb409a41"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RECORD No.  210\n",
            "n:  180\n",
            "RECORD No.  212\n",
            "n:  180\n",
            "RECORD No.  213\n",
            "n:  180\n",
            "RECORD No.  214\n",
            "n:  180\n",
            "RECORD No.  215\n",
            "n:  180\n",
            "RECORD No.  217\n",
            "n:  180\n",
            "RECORD No.  219\n",
            "n:  180\n",
            "RECORD No.  220\n",
            "n:  180\n",
            "RECORD No.  221\n",
            "n:  180\n",
            "RECORD No.  222\n",
            "n:  180\n",
            "RECORD No.  223\n",
            "n:  180\n",
            "RECORD No.  228\n",
            "n:  180\n",
            "RECORD No.  230\n",
            "n:  180\n",
            "RECORD No.  231\n",
            "n:  180\n",
            "RECORD No.  232\n",
            "n:  180\n",
            "RECORD No.  233\n",
            "n:  180\n",
            "RECORD No.  234\n",
            "n:  180\n",
            "segregate_signal_data:  3060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "superlet "
      ],
      "metadata": {
        "id": "QnfQxhBZ0fya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/TransylvanianInstituteOfNeuroscience/Superlets/blob/main/python/superlet.py\n",
        "\n",
        "import numpy as np\n",
        "from scipy.signal import fftconvolve\n",
        "\n",
        "\n",
        "def superlet(\n",
        "    data_arr,\n",
        "    samplerate,\n",
        "    scales,\n",
        "    order_max,\n",
        "    order_min=1,\n",
        "    c_1=3,\n",
        "    adaptive=False,\n",
        "):\n",
        "\n",
        "    \"\"\"\n",
        "    Performs Superlet Transform (SLT) according to Moca et al. [1]_\n",
        "    Both multiplicative SLT and fractional adaptive SLT are available. \n",
        "    The former is recommended for a narrow frequency band of interest, \n",
        "    whereas the  is better suited for the analysis of a broad range \n",
        "    of frequencies.\n",
        "    A superlet (SL) is a set of Morlet wavelets with increasing number\n",
        "    of cycles within the Gaussian envelope. Hence the bandwith \n",
        "    is constrained more and more with more cycles yielding a sharper\n",
        "    frequency resolution. Complementary the low cycle numbers will give a\n",
        "    high time resolution. The SLT then is the geometric mean \n",
        "    of the set of individual wavelet transforms, combining both wide\n",
        "    and narrow-bandwidth wavelets into a super-resolution estimate.\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_arr : nD :class:`numpy.ndarray`\n",
        "        Uniformly sampled time-series data\n",
        "        The 1st dimension is interpreted as the time axis\n",
        "    samplerate : float\n",
        "        Samplerate of the time-series in Hz\n",
        "    scales : 1D :class:`numpy.ndarray`\n",
        "        Set of scales to use in wavelet transform. \n",
        "        Note that for the SL Morlet the relationship\n",
        "        between scale and frequency simply is s(f) = 1/(2*pi*f)\n",
        "        Need to be ordered high to low for `adaptive=True`\n",
        "    order_max : int\n",
        "        Maximal order of the superlet set. Controls the maximum\n",
        "        number of cycles within a SL together\n",
        "        with the `c_1` parameter: c_max = c_1 * order_max\n",
        "    order_min : Minimal order of the superlet set. Controls \n",
        "        the minimal number of cycles within a SL together\n",
        "        with the `c_1` parameter: c_min = c_1 * order_min\n",
        "        Note that for admissability reasons c_min should be at least 3!\n",
        "    c_1 : int\n",
        "        Number of cycles of the base Morlet wavelet. If set to lower\n",
        "        than 3 increase `order_min` as to never have less than 3 cycles\n",
        "        in a wavelet!\n",
        "    adaptive : bool\n",
        "        Wether to perform multiplicative SLT or fractional adaptive SLT.\n",
        "        If set to True, the order of the wavelet set will increase\n",
        "        linearly with the frequencies of interest from `order_min` \n",
        "        to `order_max`. If set to False the same SL will be used for\n",
        "        all frequencies.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    gmean_spec : :class:`numpy.ndarray`\n",
        "        Complex time-frequency representation of the input data. \n",
        "        Shape is (len(scales), data_arr.shape[0], data_arr.shape[1]).\n",
        "    Notes\n",
        "    -----\n",
        "    .. [1] Moca, Vasile V., et al. \"Time-frequency super-resolution with superlets.\" \n",
        "       Nature communications 12.1 (2021): 1-18.\n",
        " \n",
        " \n",
        "    \"\"\"\n",
        "\n",
        "    # adaptive SLT\n",
        "    if adaptive:\n",
        "\n",
        "        gmean_spec = FASLT(data_arr, samplerate, scales, order_max, order_min, c_1)\n",
        "\n",
        "    # multiplicative SLT\n",
        "    else:\n",
        "\n",
        "        gmean_spec = multiplicativeSLT(\n",
        "            data_arr, samplerate, scales, order_max, order_min, c_1\n",
        "        )\n",
        "\n",
        "    return gmean_spec\n",
        "\n",
        "\n",
        "def multiplicativeSLT(data_arr, samplerate, scales, order_max, order_min=1, c_1=3):\n",
        "\n",
        "    dt = 1 / samplerate\n",
        "    # create the complete multiplicative set spanning\n",
        "    # order_min - order_max\n",
        "    cycles = c_1 * np.arange(order_min, order_max + 1)\n",
        "    order_num = order_max + 1 - order_min # number of different orders\n",
        "    SL = [MorletSL(c) for c in cycles]\n",
        "\n",
        "    # lowest order\n",
        "    gmean_spec = cwtSL(data_arr, SL[0], scales, dt)\n",
        "    gmean_spec = np.power(gmean_spec, 1 / order_num)\n",
        "\n",
        "    for wavelet in SL[1:]:\n",
        "\n",
        "        spec = cwtSL(data_arr, wavelet, scales, dt)\n",
        "        gmean_spec *= np.power(spec, 1 / order_num)\n",
        "\n",
        "    return gmean_spec\n",
        "\n",
        "\n",
        "def FASLT(data_arr, samplerate, scales, order_max, order_min=1, c_1=3):\n",
        "\n",
        "    \"\"\" Fractional adaptive SL transform\n",
        "    For non-integer orders fractional SLTs are\n",
        "    calculated in the interval [order, order+1) via:\n",
        "    \n",
        "    R(o_f) = R_1 * R_2 * ... * R_i * R_i+1 ** alpha \n",
        "    with o_f = o_i + alpha\n",
        "    \"\"\"\n",
        "\n",
        "    dt = 1 / samplerate\n",
        "    # frequencies of interest\n",
        "    # from the scales for the SL Morlet\n",
        "    fois = 1 / (2 * np.pi * scales)\n",
        "    orders = compute_adaptive_order(fois, order_min, order_max)\n",
        "\n",
        "    # create the complete superlet set from\n",
        "    # all enclosed integer orders\n",
        "    orders_int = np.int32(np.floor(orders))\n",
        "    cycles = c_1 * np.unique(orders_int)\n",
        "    SL = [MorletSL(c) for c in cycles]\n",
        "\n",
        "    # every scale needs a different exponent\n",
        "    # for the geometric mean\n",
        "    exponents = 1 / (orders - order_min + 1)\n",
        "\n",
        "    # which frequencies/scales use the same integer orders SL\n",
        "    order_jumps = np.where(np.diff(orders_int))[0]\n",
        "    # each frequency/scale will have its own multiplicative SL\n",
        "    # which overlap -> higher orders have all the lower orders\n",
        "\n",
        "    # the fractions\n",
        "    alphas = orders % orders_int\n",
        "\n",
        "    # 1st order\n",
        "    # lowest order is needed for all scales/frequencies\n",
        "    gmean_spec = cwtSL(data_arr, SL[0], scales, dt)  # 1st order <-> order_min\n",
        "    # Geometric normalization according to scale dependent order\n",
        "    gmean_spec = np.power(gmean_spec.T, exponents).T\n",
        "\n",
        "    # we go to the next scale and order in any case..\n",
        "    # but for order_max == 1 for which order_jumps is empty\n",
        "    last_jump = 1\n",
        "\n",
        "    for i, jump in enumerate(order_jumps):\n",
        "\n",
        "        # relevant scales for the next order\n",
        "        scales_o = scales[last_jump:]\n",
        "        # order + 1 spec\n",
        "        next_spec = cwtSL(data_arr, SL[i + 1], scales_o, dt)\n",
        "\n",
        "        # which fractions for the current next_spec\n",
        "        # in the interval [order, order+1)\n",
        "        scale_span = slice(last_jump, jump + 1)\n",
        "        gmean_spec[scale_span, :] *= np.power(\n",
        "            next_spec[: jump - last_jump + 1].T,\n",
        "            alphas[scale_span] * exponents[scale_span],\n",
        "        ).T\n",
        "\n",
        "        # multiply non-fractional next_spec for\n",
        "        # all remaining scales/frequencies\n",
        "        gmean_spec[jump + 1 :] *= np.power(\n",
        "            next_spec[jump - last_jump + 1 :].T, exponents[jump + 1 :]\n",
        "        ).T\n",
        "\n",
        "        # go to the next [order, order+1) interval\n",
        "        last_jump = jump + 1\n",
        "\n",
        "    return gmean_spec\n",
        "\n",
        "\n",
        "class MorletSL:\n",
        "    def __init__(self, c_i=3, k_sd=5):\n",
        "\n",
        "        \"\"\" The Morlet formulation according to\n",
        "        Moca et al. shifts the admissability criterion from\n",
        "        the central frequency to the number of cycles c_i\n",
        "        within the Gaussian envelope which has a constant \n",
        "        standard deviation of k_sd.\n",
        "        \"\"\"\n",
        "\n",
        "        self.c_i = c_i\n",
        "        self.k_sd = k_sd\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.time(*args, **kwargs)\n",
        "\n",
        "    def time(self, t, s=1.0):\n",
        "\n",
        "        \"\"\"\n",
        "        Complext Morlet wavelet in the SL formulation.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        t : float\n",
        "            Time. If s is not specified, this can be used as the\n",
        "            non-dimensional time t/s.\n",
        "        s : float\n",
        "            Scaling factor. Default is 1.\n",
        "        Returns\n",
        "        -------\n",
        "        out : complex\n",
        "            Value of the Morlet wavelet at the given time\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        ts = t / s\n",
        "        # scaled time spread parameter\n",
        "        # also includes scale normalisation!\n",
        "        B_c = self.k_sd / (s * self.c_i * (2 * np.pi) ** 1.5)\n",
        "\n",
        "        output = B_c * np.exp(1j * ts)\n",
        "        output *= np.exp(-0.5 * (self.k_sd * ts / (2 * np.pi * self.c_i)) ** 2)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def fourier_period(scale):\n",
        "\n",
        "    \"\"\"\n",
        "    This is the approximate Morlet fourier period\n",
        "    as used in the source publication of Moca et al. 2021\n",
        "    Note that w0 (central frequency) is always 1 in this \n",
        "    Morlet formulation, hence the scales are not compatible\n",
        "    to the standard Wavelet definitions!\n",
        "    \"\"\"\n",
        "\n",
        "    return 2 * np.pi * scale\n",
        "\n",
        "\n",
        "def scale_from_period(period):\n",
        "\n",
        "    return period / (2 * np.pi)\n",
        "\n",
        "\n",
        "def cwtSL(data, wavelet, scales, dt):\n",
        "\n",
        "    \"\"\"\n",
        "    The continuous Wavelet transform specifically\n",
        "    for Morlets with the Superlet formulation\n",
        "    of Moca et al. 2021.\n",
        "    - Morlet support gets adjusted by number of cycles\n",
        "    - normalisation is with 1/(scale * 4pi)\n",
        "    - this way the norm of the spectrum (modulus) \n",
        "      at the corresponding harmonic frequency is the \n",
        "      harmonic signal's amplitude\n",
        "    Notes\n",
        "    -----\n",
        "    \n",
        "    The time axis is expected to be along the 1st dimension.\n",
        "    \"\"\"\n",
        "\n",
        "    # wavelets can be complex so output is complex\n",
        "    output = np.zeros((len(scales),) + data.shape, dtype=np.complex64)\n",
        "\n",
        "    # this checks if really a Superlet Wavelet is being used\n",
        "    if not isinstance(wavelet, MorletSL):\n",
        "        raise ValueError(\"Wavelet is not of MorletSL type!\")\n",
        "\n",
        "    # 1st axis is time\n",
        "    slices = [None for _ in data.shape]\n",
        "    slices[0] = slice(None)\n",
        "\n",
        "    # compute in time\n",
        "    for ind, scale in enumerate(scales):\n",
        "\n",
        "        t = _get_superlet_support(scale, dt, wavelet.c_i)\n",
        "        # sample wavelet and normalise\n",
        "        norm = dt ** 0.5 / (4 * np.pi)\n",
        "        wavelet_data = norm * wavelet(t, scale)  # this is an 1d array for sure!\n",
        "        output[ind, :] = fftconvolve(data, wavelet_data[tuple(slices)], mode=\"same\")\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def _get_superlet_support(scale, dt, cycles):\n",
        "\n",
        "    \"\"\"\n",
        "    Effective support for the convolution is here not only \n",
        "    scale but also cycle dependent.\n",
        "    \"\"\"\n",
        "\n",
        "    # number of points needed to capture wavelet\n",
        "    M = 10 * scale * cycles / dt\n",
        "    # times to use, centred at zero\n",
        "    t = np.arange((-M + 1) / 2.0, (M + 1) / 2.0) * dt\n",
        "\n",
        "    return t\n",
        "\n",
        "\n",
        "def compute_adaptive_order(freq, order_min, order_max):\n",
        "\n",
        "    \"\"\"\n",
        "    Computes the superlet order for a given frequency of interest \n",
        "    for the fractional adaptive SLT (FASLT) according to \n",
        "    equation 7 of Moca et al. 2021.\n",
        "    \n",
        "    This is a simple linear mapping between the minimal\n",
        "    and maximal order onto the respective minimal and maximal\n",
        "    frequencies. \n",
        "    Note that `freq` should be ordered low to high.\n",
        "    \"\"\"\n",
        "\n",
        "    f_min, f_max = freq[0], freq[-1]\n",
        "\n",
        "    assert f_min < f_max\n",
        "\n",
        "    order = (order_max - order_min) * (freq - f_min) / (f_max - f_min)\n",
        "\n",
        "    # return np.int32(order_min + np.rint(order))\n",
        "    return order_min + order\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Some test data akin to figure 3 of the source publication\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # to get sth for the eyes ;)\n",
        "    import matplotlib.pyplot as ppl\n",
        "    fs = 360\n",
        "    # frequencies of interest in Hz\n",
        "    foi = np.linspace(1, 100, 50)\n",
        "    scales = scale_from_period(1 / foi)\n",
        "    \n",
        "    index1 = -1\n",
        "    index2 = 0\n",
        "    for i in range(len(segregate_signal_data)):\n",
        "\n",
        "      index2 = index2 + 1\n",
        "      signal = segregate_signal_data[i]\n",
        "      spec = superlet(\n",
        "          signal,\n",
        "          samplerate=fs,\n",
        "          scales=scales,\n",
        "          order_max=30,\n",
        "          order_min=1,\n",
        "          c_1=5,\n",
        "          adaptive=True,\n",
        "      )\n",
        "\n",
        "      # amplitude scalogram\n",
        "      ampls = np.abs(spec)\n",
        "      fig, (ax1, ax2) = ppl.subplots(2, 1,\n",
        "                                    sharex=True,\n",
        "                                    gridspec_kw={\"height_ratios\": [1, 3]},\n",
        "                                    figsize=(5,5))\n",
        "\n",
        "      ax1.plot(np.arange(signal.size) / fs*10000, signal, c='cornflowerblue')\n",
        "      ax1.set_ylabel('signal (a.u.)')\n",
        "      #ax1.set_xlabel('time')\n",
        "      \n",
        "      extent = [0, len(signal) / fs*10000, foi[0], foi[-1]]\n",
        "      im = ax2.imshow(np.squeeze(ampls), cmap=\"jet\", aspect=\"auto\", extent=extent, origin='lower')\n",
        "      \n",
        "      ppl.colorbar(im,ax = ax2, orientation='horizontal',\n",
        "                  shrink=0.7, pad=0.2, label='amplitude (a.u.)')\n",
        "      \n",
        "    # ax2.plot([0, len(signal[:3600]) / fs*10000], [20, 20], \"--\", c='0.5')\n",
        "    # ax2.plot([0, len(signal[:3600]) / fs*10000], [40, 40], \"--\", c='0.5')\n",
        "    # ax2.plot([0, len(signal[:3600]) / fs*10000], [60, 60], \"--\", c='0.5')\n",
        "      \n",
        "      ax2.set_xlabel(\"time (s)\")    \n",
        "      ax2.set_ylabel(\"frequency (Hz)\")\n",
        "\n",
        "      fig.tight_layout()\n",
        "      extent = ax2.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
        "\n",
        "      if(i%180 == 0):\n",
        "        index1 = index1 + 1\n",
        "        index2 = 1\n",
        "\n",
        "\n",
        "      fig.savefig('/content/drive/MyDrive/Dataset/mit-bih-arrhythmia-database_SLT/'\n",
        "        +str(record_no[index1])+'_'+str(index2)+'.png', bbox_inches=extent)\n",
        "      \n",
        "  \n",
        "       \n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR1TP0p50h8w",
        "outputId": "b992ef28-b375-45f5-f1f8-9d34006fb131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:360: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wfdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wru2xCbNgayS",
        "outputId": "4710da95-0009-4eff-f5b7-af1478785e65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wfdb\n",
            "  Downloading wfdb-4.0.0-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 22.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.3.5)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.7.3)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from wfdb) (3.2.2)\n",
            "Requirement already satisfied: SoundFile<0.12.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (0.11.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.10.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<4.0.0,>=3.2.2->wfdb) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->wfdb) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib<4.0.0,>=3.2.2->wfdb) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from SoundFile<0.12.0,>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->SoundFile<0.12.0,>=0.10.0->wfdb) (2.21)\n",
            "Installing collected packages: wfdb\n",
            "Successfully installed wfdb-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-VnU34sf9QU",
        "outputId": "9350f92c-5d6c-4b97-985a-308d91995c61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}